Popularizacijom generativnih modela umjetne inteligencije proteklih godina mogu se vidjeti brojni primjeri njihove primjene na prenošenje stila (engl. \textit{style transfer})\cite{jing2019neural}. Glavni cilj ovoga zadatka strojnog učenja je pretvorba postojećih slika tako da izgledaju kao da su naslikane rukom željenog slikara ili animirane u stilu zadanog studija. Kompliciraniji je problem prenošenje stila zvučnih podataka, zbog njihove promjenjivosti u vremenu, ali i poteškoća u stvaranju preciznih opisa različitih stilova. Cilj je prenijeti glazbeni žanr i zvuk zadanog stila na način da je očuvana melodijska i ritamska struktura zadanog isječka.

Difuzijski modeli\cite{yang2023diffusion} učinkovit su alat u zadacima s vizualnim generiranjem pa nude obećavajući okvir i za probleme iz audio domene. Ovaj rad nastoji reproducirati rezultate rada \textit{Music Style Transfer with Time-Varying Inversion of Diffusion Models}\cite{huang2024musicstyletransferdiffusion}. Opisat će se prethodni pristupi na čije smo se temelje oslanjali, struktura korištenog modela, njegovo učenje i rezultati te njihova evaluacija po dvije različite objektivne metrike.
